# backend/main.py
from fastapi import FastAPI, UploadFile, File, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import csv
import io
import sqlite3
from typing import Dict, List, Any
from db_setup import get_connection, init_db

app = FastAPI(title="Cascading Dropdown CSV API")

# allow CORS for local dev (adjust origins for production)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

# initialize DB
init_db()

class FilterRequest(BaseModel):
    business_unit: List[str] = []
    country: List[str] = []
    region: List[str] = []
    business_terms: List[str] = []
    sales_channel: List[str] = []

@app.post("/upload-csv")
async def upload_csv(file: UploadFile = File(...)):
    """
    Accept CSV file and insert rows into SQLite using csv + io only.
    Expected columns (header): Business Unit,Country,Region,Business Terms,Sales Channel
    """
    if not file.filename.lower().endswith((".csv", ".txt")):
        raise HTTPException(status_code=400, detail="Upload a CSV file")

    content = await file.read()
    text = content.decode("utf-8", errors="ignore")
    reader = csv.reader(io.StringIO(text))

    # Expect header row first
    try:
        header = next(reader)
    except StopIteration:
        raise HTTPException(400, "Empty CSV")

    # Normalize header: strip and lower for matching
    norm_header = [h.strip().lower() for h in header]

    # mapping indexes
    def idx_of(names):
        for name in names:
            if name in norm_header:
                return norm_header.index(name)
        return None

    idx_business_unit = idx_of(["business unit", "business_unit", "businessunit"])
    idx_country = idx_of(["country"])
    idx_region = idx_of(["region"])
    idx_business_terms = idx_of(["business terms", "business_terms", "businessterms"])
    idx_sales_channel = idx_of(["sales channel", "sales_channel", "saleschannel"])

    if None in (idx_business_unit, idx_country, idx_region, idx_business_terms, idx_sales_channel):
        raise HTTPException(400, "CSV header must contain Business Unit, Country, Region, Business Terms, Sales Channel")

    conn = get_connection()
    cur = conn.cursor()
    inserted = 0

    for row in reader:
        # handle rows shorter than header
        if len(row) < len(norm_header):
            # pad with empty strings
            row = row + [""] * (len(norm_header) - len(row))
        bu = row[idx_business_unit].strip()
        country = row[idx_country].strip()
        region = row[idx_region].strip()
        bterms = row[idx_business_terms].strip()
        sales = row[idx_sales_channel].strip()
        cur.execute(
            "INSERT INTO records (business_unit, country, region, business_terms, sales_channel) VALUES (?, ?, ?, ?, ?)",
            (bu, country, region, bterms, sales)
        )
        inserted += 1

    conn.commit()
    conn.close()
    return {"status": "ok", "rows_inserted": inserted}

@app.get("/unique-values")
def unique_values():
    """
    Returns distinct values per column in JSON.
    """
    conn = get_connection()
    cur = conn.cursor()
    fields = {
        "business_unit": "business_unit",
        "country": "country",
        "region": "region",
        "business_terms": "business_terms",
        "sales_channel": "sales_channel"
    }
    result: Dict[str, List[str]] = {}
    for key, col in fields.items():
        cur.execute(f"SELECT DISTINCT {col} FROM records WHERE {col} IS NOT NULL AND TRIM({col}) <> '' ORDER BY {col} COLLATE NOCASE")
        rows = cur.fetchall()
        result[key] = [r[0] for r in rows]
    conn.close()
    return result

def build_where_clause(filters: FilterRequest):
    """
    Build SQL WHERE clause and params for provided filter lists.
    """
    clauses = []
    params: List[Any] = []
    mapping = {
        "business_unit": filters.business_unit,
        "country": filters.country,
        "region": filters.region,
        "business_terms": filters.business_terms,
        "sales_channel": filters.sales_channel
    }
    for col, vals in mapping.items():
        if vals:
            placeholders = ",".join("?" for _ in vals)
            clauses.append(f"{col} IN ({placeholders})")
            params.extend(vals)
    where = " AND ".join(clauses) if clauses else ""
    return where, params

@app.post("/filter")
def filter_values(filters: FilterRequest):
    """
    Accepts selected values (multi-select arrays) and returns unique values for remaining columns
    filtered by the selections.
    """
    conn = get_connection()
    cur = conn.cursor()
    where, params = build_where_clause(filters)

    fields = ["business_unit", "country", "region", "business_terms", "sales_channel"]
    response: Dict[str, List[str]] = {}

    for col in fields:
        query = f"SELECT DISTINCT {col} FROM records"
        if where:
            query += f" WHERE {where}"
        query += f" ORDER BY {col} COLLATE NOCASE"
        cur.execute(query, params)
        rows = cur.fetchall()
        response[col] = [r[0] for r in rows]
    conn.close()
    return response

@app.get("/search")
def search(q: str):
    """
    Search top 10 matching countries (partial, case-insensitive)
    """
    q_like = f"%{q}%"
    conn = get_connection()
    cur = conn.cursor()
    cur.execute("SELECT DISTINCT country FROM records WHERE country LIKE ? ORDER BY country COLLATE NOCASE LIMIT 10", (q_like,))
    rows = cur.fetchall()
    conn.close()
    return {"results": [r[0] for r in rows]}
